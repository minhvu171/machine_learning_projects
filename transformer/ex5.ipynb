{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f7199d-c442-4732-ab89-83bda42682a7",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 5: Machine Translation with Transformers\n",
    "\n",
    "In this exercise, we will explore the Transformer-based neural architecture by tackling a machine translation task. Machine translation involves translating text from a source language to a target language. Traditionally, machine translation was performed using recurrent neural network (RNN)-based architectures. However, the emergence of Transformers has marked a revolutionary shift in the fields of text analysis and especially machine translation.\n",
    "\n",
    "\n",
    "To complete this assignment, you will progress through four different stages (tasks):\n",
    "\n",
    "**Task 1. Data Preparation (5 points)**\n",
    "\n",
    "**Task 2. Model Architecture (5 points)**\n",
    "\n",
    "**Task 3. Training and Evaluation (5 points)**\n",
    "\n",
    "**Task 4. Autoregressive Translation (5 points)**\n",
    "\n",
    "\n",
    "### **Data**\n",
    "\n",
    "The dataset used for this exercise consists of a set of French sentenceas and their equivalent English translations.\n",
    "\n",
    "*Note:* Your dataset path should point to the \"dataset_ex5\" folder, which contains two CSV files, each containing 137860 short sentences:\n",
    "\n",
    "    small_vocab_fr.csv: French sentences.\n",
    "    small_vocab_en.csv: Corresponding English translations.\n",
    "\n",
    "Be mindful of any extra folder levels that may be created when extracting the \"dataset_ex5.zip\" file.\n",
    "\n",
    "### **Useful links**\n",
    "\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "\n",
    "\n",
    "After downloading the data and setting up the folders, you are ready to begin the exercise tasks. Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8445f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = True   # You can set it to True if you want to run inference on your trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4929157-7d8f-4e84-85f6-c56ea7093ae1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "188b80bd0b4c8442090aaa7246bee938",
     "grade": false,
     "grade_id": "cell-172f7e1657a03eb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Add path to the folder containing csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959359d2-e60b-4dec-a5eb-d7dabe3f1a5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"dataset_ex5\" # you can change the path if you want to store the dataset somewhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb6f08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8527fd780788625a34b40348b30de440",
     "grade": false,
     "grade_id": "cell-39478e54ddb16815",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6feccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds for all libraries\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1) \n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607dc4e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "535faf5a7df324791294b2fd542d2d89",
     "grade": false,
     "grade_id": "cell-815c797e06bdf55a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Select the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54ab47d-14c2-4cd0-93a1-e4efc335c13c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b59f0542e430f521a92680557a10ca8b",
     "grade": false,
     "grade_id": "cell-c544c464735ece56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ed6c0-92b9-4ca5-8b9f-71995799314f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "851f4281950105edf2038c35a19db963",
     "grade": false,
     "grade_id": "cell-91357d14fc99d39d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 1: Data Preparation (5 Points)\n",
    "\n",
    "In this task, you will preprocess the dataset to convert it into a format suitable for input to a Transformer neural model. Each subtask focuses on a specific step in the preprocessing pipeline.\n",
    "\n",
    "### Summary of Tasks for This Stage\n",
    "\n",
    "**Task 1.1: Tokenizaion** (1 point)\n",
    "\n",
    "**Task 1.2: Building Vocabulary** (1 point)\n",
    "\n",
    "**Task 1.3: Sentence Embedding** (1 points)\n",
    "\n",
    "**Task 1.4: Positional Encodding** (2 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9febf38-0a1a-4ff3-94a7-eb232c21eef1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f4723736e3e4512d6d08504b7a0dbd6",
     "grade": false,
     "grade_id": "cell-291860bd3393c1d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.1: Tokenizaion\n",
    "\n",
    "\n",
    "1. Lowercasing: Convert all characters in the sentence to lowercase.\n",
    "2. Filtering Characters: Define a set of characters to be removed from the sentences, replacing them with an empty string.\n",
    "3. Splitting: Split the sentence into tokens based on spaces.\n",
    "   \n",
    "Run the cell below to load the data, observe basic statistics, and examine some sample sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ecf7ac-b2ce-4e9e-9560-8bc53c616282",
   "metadata": {
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 137860 English sentences in data\n",
      "There are 137860 French sentences in data\n",
      "Here are some examples:\n",
      "----------\n",
      "new jersey is sometimes quiet during autumn \n",
      "new jersey est parfois calme pendant l' automne \n",
      "----------\n",
      "they like strawberries \n",
      "ils aiment les fraises \n",
      "----------\n",
      "she plans to visit the united states next may .\n",
      "elle envisage de se rendre aux états-unis en mai prochain .\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "en_df = pd.read_csv(os.path.join(path , 'small_vocab_en.csv'), header=None, usecols=[0])\n",
    "fr_df = pd.read_csv(os.path.join(path, 'small_vocab_fr.csv'), header=None, usecols=[0])\n",
    "\n",
    "english_sentences = en_df[0].values\n",
    "french_sentences = fr_df[0].values\n",
    "\n",
    "print(f'There are {len(english_sentences)} English sentences in data')\n",
    "print(f'There are {len(french_sentences)} French sentences in data')\n",
    "print('Here are some examples:')\n",
    "e = [ 0, 1000, 3000]\n",
    "for i in e:\n",
    "    print(10*\"-\")\n",
    "    print(english_sentences[i])\n",
    "    print(french_sentences[i])\n",
    "print(100*\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30eefb6-5483-4cf5-839c-eb72aa892eb8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d56cb799102b3f767bfccf73c33b13e3",
     "grade": false,
     "grade_id": "cell-e1accedab7f1151b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Complete the \"tokenize\" function by filling in the blanks based on the detailed guidance provided within the code comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a18098-1a7f-4758-84f4-4a7f6bfa40d3",
   "metadata": {
    "deletable": false,
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e136e2d6e0d0fe41dcc0ed1b4265e4b3",
     "grade": false,
     "grade_id": "cell-d953178b4a066fcc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "['new', 'jersey', 'is', 'sometimes', 'quiet', 'during', 'autumn']\n",
      "['new', 'jersey', 'est', 'parfois', 'calme', 'pendant', \"l'\", 'automne']\n",
      "----------\n",
      "['they', 'like', 'strawberries']\n",
      "['ils', 'aiment', 'les', 'fraises']\n",
      "----------\n",
      "['she', 'plans', 'to', 'visit', 'the', 'united', 'states', 'next', 'may']\n",
      "['elle', 'envisage', 'de', 'se', 'rendre', 'aux', 'étatsunis', 'en', 'mai', 'prochain']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize function \n",
    "def tokenize(sentences):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of sentences by:\n",
    "    1. Converting all text to lowercase.\n",
    "    2. Removing special characters listed in \"filters\".\n",
    "    Hint: you can use \"str.maketrans\" to creates a translation table to remove unwanted characters defined in \"filters\".\n",
    "    3. Splitting each sentence into a list of words.\n",
    "    \"\"\"\n",
    "    filters = '.?!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n'\n",
    "    \n",
    "    # Create translation table to remove unwanted characters\n",
    "    translator = str.maketrans('', '', filters)\n",
    "\n",
    "    tokenized_list = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(translator)\n",
    "        tokens = sentence.split()\n",
    "        tokenized_list.append(tokens)\n",
    "        \n",
    "    return tokenized_list\n",
    "    \n",
    "# Tokenize English and French sentences\n",
    "tokenized_en = tokenize(english_sentences)\n",
    "tokenized_fr = tokenize(french_sentences)\n",
    "for i in e:\n",
    "    print(10*\"-\")\n",
    "    print(tokenized_en[i])\n",
    "    print(tokenized_fr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc71a52-0148-4bce-af72-799047b0f653",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0907496be0bbf0e8a9587a38d054ac63",
     "grade": false,
     "grade_id": "cell-5c42169eb0d9ba7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.2: Building Vocabulary\n",
    "\n",
    "In this step, we will convert tokenized sentences into lists of integers. This is achieved by defining a dictionary of unique words for each language and assigning a unique integer to each word.\n",
    "\n",
    "In this exercise, we are building a word-level dictionary, where each entry in the dictionary represents a unique word.\n",
    "\n",
    "In addition to the set of unique words in the dataset, the vocabulary must include three special tokens:\n",
    "\n",
    "1.  PAD: Padding Token (0)\n",
    "2.  SOS: Start of Sentence (1)\n",
    "3.  EOS: End of Sentence (2)\n",
    "\n",
    "Complete the \"build_vocab\" function by filling in the blanks according to the provided instructions in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee1d488c-b866-46da-91c9-857bc7540d7b",
   "metadata": {
    "deletable": false,
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54b4b871a691fb80fb59f818abe16af6",
     "grade": false,
     "grade_id": "cell-acd8f7a88e74d5a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples from our English dictionary: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "word: <PAD>, index: 0\n",
      "word: <SOS>, index: 1\n",
      "word: <EOS>, index: 2\n",
      "word: new, index: 3\n",
      "word: jersey, index: 4\n",
      "word: is, index: 5\n",
      "word: sometimes, index: 6\n",
      "word: quiet, index: 7\n",
      "word: during, index: 8\n",
      "word: autumn, index: 9\n",
      "__________\n",
      "index: 0, word: <PAD>\n",
      "index: 1, word: <SOS>\n",
      "index: 2, word: <EOS>\n",
      "index: 3, word: new\n",
      "index: 4, word: jersey\n",
      "index: 5, word: is\n",
      "index: 6, word: sometimes\n",
      "index: 7, word: quiet\n",
      "index: 8, word: during\n",
      "index: 9, word: autumn\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary with special tokens\n",
    "def build_vocab(tokenized_sentences):\n",
    "    special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "\n",
    "    counter = Counter(token for sentence in tokenized_sentences for token in sentence)\n",
    "    vocab = special_tokens + list(counter.keys())\n",
    "    \n",
    "    # Create mappings\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    \n",
    "    return word2idx, idx2word\n",
    "\n",
    "en_word2idx, en_idx2word = build_vocab(tokenized_en)\n",
    "fr_word2idx, fr_idx2word = build_vocab(tokenized_fr)\n",
    "\n",
    "print(\"Here are some examples from our English dictionary: \")\n",
    "print(100 * \"-\")\n",
    "\n",
    "# Display first 10 words and their indices from en_word2idx\n",
    "for i, (key, value) in enumerate(en_word2idx.items()):\n",
    "    print(f'word: {key}, index: {value}')\n",
    "    if i == 9:  # After 10 iterations, break\n",
    "        break\n",
    "\n",
    "print(10 * \"_\")\n",
    "\n",
    "# Display first 10 indices and their words from en_idx2word\n",
    "for i, (key, value) in enumerate(en_idx2word.items()):\n",
    "    print(f'index: {key}, word: {value}')\n",
    "    if i == 9:  # After 10 iterations, break\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604ca38-063e-46cb-a40e-57192653a316",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc164a3386abefc31af298f532ab98d0",
     "grade": false,
     "grade_id": "cell-2b2c9232a9907c80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Dataset Class\n",
    "\n",
    "In this step, we will use a custom dataset class specifically designed for our translation task. You do not need to implement anything for this step, as the dataset class is already provided for you. This class incorporates essential preprocessing steps, such as padding, truncation, and the addition of special tokens.\n",
    "\n",
    "As discussed earlier, sentences in our dataset have varying lengths. To ensure all sentences are of the same length (a requirement for the Transformer model), we will define a fixed length for input sequences. The preprocessing steps performed by the dataset class include:\n",
    "\n",
    "* Special Tokens: The 'SOS' token is added at the beginning of each sentence, and the 'EOS' token is added at the end.\n",
    "* Truncation: Sentences that exceed the defined maximum length will be truncated to fit the specified length.\n",
    "* Padding: The 'PAD' token is appended to sentences shorter than the maximum length until they reach the required length.\n",
    "\n",
    "Take some time to go through the dataset class and its methods to observe how these preprocessing steps are implemented. Understanding the class structure will help you in tasks where you might need to customize or extend the dataset functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742ff0d6-758b-43c6-a870-aab4a73746dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch: tensor([[  1,  39,  65,   5,   6, 104,  15,  64,   2,   0]])\n",
      "torch.Size([1, 10])\n",
      "__________\n",
      "Target batch: tensor([[ 1, 58,  5,  6, 87,  8, 57,  2,  0,  0]])\n",
      "torch.Size([1, 10])\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "# Dataset class with padding applied in __getitem__\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, seq_len=30):\n",
    "        self.src_sentences = src_sentences\n",
    "        self.tgt_sentences = tgt_sentences\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def pad_sequence(self, tokens, vocab, is_target=False):\n",
    "        \"\"\"\n",
    "        Pads a sequence of tokens to the fixed length `seq_len`.\n",
    "        Adds <SOS> at the start, <EOS> at the end, and pads with <PAD>.\n",
    "        Trims if the sequence is longer than `seq_len`.\n",
    "        \"\"\"\n",
    "        tokens = [vocab[\"<SOS>\"]] + [vocab.get(token, vocab[\"<PAD>\"]) for token in tokens]\n",
    "        tokens.append(vocab[\"<EOS>\"])  \n",
    "        tokens = tokens[:self.seq_len]  \n",
    "        tokens += [vocab[\"<PAD>\"]] * (self.seq_len - len(tokens))  \n",
    "        return tokens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        src_tokens = self.src_sentences[idx]\n",
    "        tgt_tokens = self.tgt_sentences[idx]\n",
    "        \n",
    "        # Apply padding to both the source and target sentences\n",
    "        src_padded = self.pad_sequence(src_tokens, self.src_vocab, is_target=False)\n",
    "        tgt_padded = self.pad_sequence(tgt_tokens, self.tgt_vocab, is_target=True)\n",
    "        \n",
    "        # Convert to tensors and move to device (GPU or CPU)\n",
    "        src_item = torch.tensor(src_padded).to(device)\n",
    "        tgt_item = torch.tensor(tgt_padded).to(device)\n",
    "    \n",
    "        return src_item, tgt_item\n",
    "\n",
    "# Instantiate and test the dataset, let the French be as source language and English as target language.\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test the DataLoader\n",
    "for src_batch, tgt_batch in dataloader:\n",
    "    print(\"Source batch:\", src_batch)\n",
    "    print(src_batch.size())\n",
    "    print(10*\"_\")\n",
    "    print(\"Target batch:\", tgt_batch)\n",
    "    print(tgt_batch.size())\n",
    "    print(10*\"_\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbf6fe-050c-4357-ae8f-112a4021b231",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a920ba916dac6fa8032a24c0603867eb",
     "grade": false,
     "grade_id": "cell-5ddb30e4fc5234fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.3: Sentence Embedding\n",
    "\n",
    "Words, by themselves, are discrete symbols that neural networks cannot process directly. To make them understandable to the model, we use **embedding layers**. These layers transform words or tokens into dense, fixed-size vectors, where each word is represented by a unique vector. The embedding layer maps words into a continuous vector space, enabling semantically similar words to be closer to each other in this space. This approach is far more compact and efficient than sparse, high-dimensional representations like one-hot encoding.\n",
    "\n",
    "Embedding layers are particularly useful in natural language processing tasks such as **machine translation**, where words in different languages must be represented in a way that enables the model to learn their relationships.\n",
    "\n",
    "In this step, you are asked to define separate PyTorch embedding layers for both the source and target languages, and then pass the src_batch and tgt_batch through these layers. In the cell below, complete the code by filling in the blanks according to the provided instructions. After running the cell, pay attention to the input and output dimensions of the embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fe7f794-94bc-4332-a186-7c0d11fc218f",
   "metadata": {
    "deletable": false,
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e641ffdf106f543f00d6a776e3963eb",
     "grade": false,
     "grade_id": "cell-fab72a3e23c8b68e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 128])\n",
      "__________\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "vsize_src = len(fr_word2idx)\n",
    "vsize_tgt = len(en_word2idx)\n",
    "\n",
    "# data: let the French be as source language and English as target language.\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Use 'next' to get a batch from the DataLoader iterator\n",
    "src_batch, tgt_batch = next(iter(dataloader))\n",
    "\n",
    "embedding_fr = nn.Embedding(num_embeddings=vsize_src, embedding_dim=embedding_size)\n",
    "embedding_fr.to(device)\n",
    "output_embedding_fr = embedding_fr(src_batch)\n",
    "\n",
    "\n",
    "embedding_en = nn.Embedding(num_embeddings=vsize_tgt, embedding_dim=embedding_size)\n",
    "embedding_en.to(device)\n",
    "output_embedding_en = embedding_en(tgt_batch) \n",
    "\n",
    "print(10*\"_\")\n",
    "print(src_batch.size())\n",
    "print(output_embedding_fr.size())\n",
    "print(10*\"_\")\n",
    "print(tgt_batch.size())\n",
    "print(output_embedding_en.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ae0f-ece1-4596-8037-89631b8d2075",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "478bcf1a7168a93463c0482b18b80bbf",
     "grade": false,
     "grade_id": "cell-8372a80b53e83a10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.4: Positional encoding\n",
    "\n",
    "In sequence models like the Transformer, the model needs a way to understand the relative positions of words in a sequence. Since the Transformer model does not inherently process sequential data in a time-dependent manner (unlike RNNs or LSTMs), we need to explicitly provide information about the position of each word in the input sequence.\n",
    "\n",
    "The Positional Encoding layer is used to add this positional information to the word embeddings. It generates a vector for each position in the sequence and combines it with the word embedding to provide both the content and position information. The positional encoding is computed using sine and cosine functions of different wavelengths, which allows the model to easily learn relative positions.\n",
    "\n",
    "In this step, your task is to implement the Positional Encoding layer. You should:\n",
    "\n",
    "1. Compute the positional encodings using sine and cosine functions.\n",
    "2. Register the positional encodings as a buffer so they are not considered trainable parameters.\n",
    "3. Add the positional encoding to the word embeddings during the forward pass.\n",
    "\n",
    "Once you have implemented the layer, you can test if it works correctly by running the test cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfbfdac1-3bd3-4a57-b034-4aeb97cf1b9d",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66ff2d4d083b95d6edb7f6e17233b63e",
     "grade": false,
     "grade_id": "cell-de1d08bfdff6d81e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "        # Initialize a tensor to store positional encodings for each position up to max_len\n",
    "        pos_encoding = torch.zeros(max_len, embed_size)\n",
    "        # Create a tensor for positions, where each position corresponds to a word's position in the sequence\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # 1. Create a tensor `div_term` to scale the positional encoding values. \n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, embed_size, 2).float() * (-math.log(10000.0) / embed_size)\n",
    "        )\n",
    "\n",
    "        # 2. Apply the sine function to the even indices of the positional encoding matrix.\n",
    "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # 3. Apply the cosine function to the odd indices of the positional encoding matrix.\n",
    "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Register as buffer so it is not considered as a parameter during training\n",
    "        self.register_buffer('pos_encoding', pos_encoding.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to embeddings\n",
    "        x = x * math.sqrt(self.embed_size)\n",
    "        x = x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a3335e-1dff-4fe8-aebd-8367d2359da5",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "torch.Size([1, 10, 128])\n",
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "#%% Applying positional encoding \n",
    "positional_encoding = PositionalEncoding(embedding_size, 512)\n",
    "output_pe_fr = positional_encoding (output_embedding_fr)\n",
    "output_pe_en = positional_encoding (output_embedding_en)\n",
    "print(10*\"_\")\n",
    "print(output_pe_fr.size())\n",
    "print(output_pe_en.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf7c61-c078-45c3-977e-fbefe51e3beb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29456a0467e8a115f33b88974dd4d293",
     "grade": false,
     "grade_id": "cell-093e16e5c4566696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2: Model Architecture (5 points)\n",
    "\n",
    "### Summary of Tasks for This Stage\n",
    "\n",
    "**Task 2.1: Designing a basic transformer block** (3 points)\n",
    "\n",
    "**Task 2.2: Adding Encoder and Decoder blocks** (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ff3a1-5f60-4baa-9eb9-17d899db9df5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b95686179c6ec14218111c952981a8a7",
     "grade": false,
     "grade_id": "cell-791a329ab0d9161b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 2.1: Designing a basic transformer block\n",
    "\n",
    "In this task, you will implement a simple Transformer model. This model will take source and target sequences as input, apply embeddings and positional encodings, pass the result through a Transformer block, and finally project the output to the target vocabulary space. Before passing the input through the Transformer block, you need to compute two types of masks:\n",
    "\n",
    "**Padding Mask:** This mask is applied to the source sequence and to the target sequence to prevent the model from attending to padding tokens, which should be ignored during training. The padding mask is implemented in the create_pad_mask method.\n",
    "\n",
    "**Target Mask (tgt_mask):** This mask is used to prevent the model from using future target steps to predict the current output. If the model could access future information, it would already know the solution, making training redundant. The tgt_mask helps ensure causal attention by masking out future tokens in the target sequence.\n",
    "\n",
    "These two masks are essential for enabling effective training and maintaining the correct flow of information through the model. \n",
    "\n",
    "For this task, you can use the pre-implemented embedding and positional encoding blocks. In the MySimpleTransformer template provided below, fill in the blanks as instructed in the code. Once you have implemented the MySimpleTransformer class, you can test the correctness of your solution by running the test cell. \n",
    "\n",
    "You may receive a warning about using 'batch_first' during the initialization of the Transformer block. Please ignore it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f4ccdb-b179-4d23-952d-bdc91600d5b6",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ff5491cc33c712ba4fdb589c0db60e",
     "grade": false,
     "grade_id": "cell-2c2066cf6ea79138",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MySimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
    "        super(MySimpleTransformer, self).__init__()\n",
    "        \n",
    "        # Embedding layer for source language tokens\n",
    "        self.src_embedding = nn.Embedding(vocab_size_src, embed_size)\n",
    "        # embedding layer for target language tokens\n",
    "        self.tgt_embedding = nn.Embedding(vocab_size_tgt, embed_size)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
    "        # Transformer block \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # Final linear layer to project transformer output to vocab size (Hint: use nn.Linear)\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size_tgt)\n",
    "        \n",
    "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):      \n",
    "        # 1. Get embeddings for source and target.\n",
    "        src_embedded = self.src_embedding(src)\n",
    "        tgt_embedded = self.tgt_embedding(tgt)      \n",
    "        # 2. apply positional encoding to embedded source and target\n",
    "        src_pos_encoded = self.positional_encoding(src_embedded)\n",
    "        tgt_pos_encoded = self.positional_encoding(tgt_embedded)     \n",
    "        # 3. Create a causal mask for the target to prevent seeing future tokens\n",
    "        if tgt_mask is None:\n",
    "            tgt_mask = self.get_tgt_mask(tgt)\n",
    "        # 4. Forward pass to Transformer block with masking\n",
    "        transformer_output = self.transformer(\n",
    "            src_pos_encoded,\n",
    "            tgt_pos_encoded,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "        # 5. Project to vocabulary size\n",
    "        output = self.fc_out(transformer_output)    \n",
    "        return output\n",
    "    \n",
    "    def get_tgt_mask(self, tgt):\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
    "        return tgt_mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix):\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        pad_token = 0\n",
    "        return (matrix == pad_token)\n",
    "\n",
    "def get_num_trainable_parameters(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model has {num_params} trainable parameters.')\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa97de74-2b5a-4521-9474-04f9b7112e0b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "[[  1  65   5 103  15 114   2   0   0   0]]\n",
      "[[False False False False False False False  True  True  True]]\n",
      "torch.Size([10, 10])\n",
      "[[  0. -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0. -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0. -inf -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0. -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0. -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0. -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0. -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0. -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(src_batch.size())\n",
    "print(tgt_batch.size())\n",
    "\n",
    "print(src_padding_mask.size())\n",
    "print(src_batch.cpu().detach().numpy())\n",
    "print(src_padding_mask.cpu().detach().numpy())\n",
    "\n",
    "print(tgt_mask.size())\n",
    "print(tgt_mask.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03f944-f320-4ab2-ba28-cbeb8cb7927a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ffa9c18d5dc8110338e939c9d337b22",
     "grade": false,
     "grade_id": "cell-c94bd78980ab8c0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 2.2: Adding Encoder and Decoder blocks\n",
    "\n",
    "The MySimpleTransformer class you implemented uses the Transformer module of PyTorch, which consists of two main parts: the encoder and the decoder. Each part of the model contains several layers of self-attention and feedforward neural networks, with the encoder and decoder connected by a cross-attention mechanism.\n",
    "\n",
    "**Self-Attention:** In the context of machine translation, self-attention allows each word in a sequence (either in the source or target language) to attend to every other word in the same sequence, regardless of their position. This mechanism enables the model to capture long-range dependencies and relationships within the sentence.\n",
    "\n",
    "**Cross-Attention:** This occurs in the decoder block, where the model attends to the encoder's output. In machine translation, cross-attention allows the decoder to focus on relevant parts of the input sequence (source language) when generating the output sequence (target language). It essentially \"crosses\" between the encoder and decoder, enabling the model to translate based on the context of both source and target sentences.\n",
    "\n",
    "Next, we will modify our Transformer block by manually separating the encoder and decoder components. This separation is necessary because, during inference (translation), the source sentence must pass through the encoder, and the generated target sentence must pass through the decoder one token at a time. This step is crucial since the translation process is autoregressive, meaning each word is predicted based on the previously generated words.\n",
    "\n",
    "In the cell below, complete the MyTransformer class as an updated version of our model class. This updated version will be used to train our neural machine translation system. Ensure that the encoder and decoder components are implemented separately, as this is important for managing the inference process later.\n",
    "\n",
    "\n",
    "Once you have implemented the MyTransformer class, you can test the correctness of your solution by running the test cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a05c4ec1-3f32-4d12-b0e2-a2bd1643b0de",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e19cf10486e97e5f1e11d783d36ea26",
     "grade": false,
     "grade_id": "cell-8acf47d49c2ce752",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
    "        super(MyTransformer, self).__init__()\n",
    "        # Embeddings\n",
    "        self.src_embedding = nn.Embedding(vocab_size_src, embed_size)\n",
    "        self.tgt_embedding = nn.Embedding(vocab_size_tgt, embed_size)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
    "\n",
    "        # Transformer module\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Final projection layer\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size_tgt)\n",
    "    \n",
    "    def encode(self, src, src_padding_mask):\n",
    "        # 1. Get embeddings for source \n",
    "        src_embedded = self.src_embedding(src)\n",
    "        # 2. apply positional encoding to embedded source \n",
    "        src_embedded = self.positional_encoding(src_embedded)\n",
    "        # 3. Forward pass to Transformer encoder block with src_key_padding_mask\n",
    "        encoded = self.transformer.encoder(\n",
    "            src_embedded,\n",
    "            src_key_padding_mask=src_padding_mask\n",
    "        )\n",
    "        \n",
    "        return encoded\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, tgt_padding_mask):\n",
    "        # 1. Get embeddings for target\n",
    "        tgt_embedded = self.tgt_embedding(tgt)\n",
    "        # 2. apply positional encoding to embedded target\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded)\n",
    "        # 3. Forward pass target and memory (output of encode) to Transformer decoder block with tgt_mask\n",
    "        decoded = self.transformer.decoder(\n",
    "            tgt_embedded,\n",
    "            memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask\n",
    "        )\n",
    "        \n",
    "        return decoded\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):\n",
    "        if tgt_mask is None:\n",
    "            tgt_mask = self.get_tgt_mask(tgt)        \n",
    "        # 1. pass source through encode block (name it as memory)\n",
    "        memory = self.encode(src, src_padding_mask)\n",
    "        # 2. pass target and memory through decode block\n",
    "        output_decoder = self.decode(tgt, memory, tgt_mask, tgt_padding_mask)\n",
    "        # 3. Project to vocabulary size  \n",
    "        output = self.fc_out(output_decoder)\n",
    "\n",
    "        return  output_decoder, output \n",
    "    \n",
    "    def get_tgt_mask(self, tgt):\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
    "        return tgt_mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix):\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        pad_token = 0\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478708b-68d0-4690-8bed-3629ea2e4b2d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa833b18ff0a817c3b7a1c03133e50b0",
     "grade": false,
     "grade_id": "cell-2f77cd749e40453a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 3: Training and Validation (5 points)\n",
    "\n",
    "So far, we have defined our dataset class and the Transformer model. The next step is to train and validate the model. We will split the data into training and validation sets, with an 80% training and 20% validation ratio, and run the training and validation loops accordingly.\n",
    "\n",
    "For the model, we will define a simple Transformer with a hidden dimension of 512, 4 encoder layers, 4 decoder layers, and 6 attention heads. We will use cross-entropy loss, which is well-suited for Transformer-based machine translation because it measures the difference between the predicted probability distribution and the true distribution for each token in the sequence. This loss function helps the model optimize the prediction accuracy for each word in the target sequence. Additionally, we will use the Adam optimizer to efficiently minimize the loss. \n",
    "\n",
    "First, run the two cells below to define the data and model with the specified hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f93453c6-4922-4ddf-b8dc-19558256fceb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3ac1b60f442e9b10eccc70525247757",
     "grade": false,
     "grade_id": "cell-39da44537b108c0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 110288, Validation samples: 27572\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "bs = 256\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=11)\n",
    "number_of_sentences = len(tokenized_fr)\n",
    "train_size = int((0.8)*number_of_sentences)\n",
    "test_size = int(number_of_sentences - train_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, drop_last=True)\n",
    "print(f'Training samples: {len(train_dataset)}, Validation samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efd32c9e-9868-4f8a-819d-6816332a9ea7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ada45fd309f153dcb7c3f001c5acddc8",
     "grade": false,
     "grade_id": "cell-47986e3c9b4441ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "embedding_size = 240 # embed_dim must be divisible by num_heads\n",
    "vsize_src = len(fr_word2idx) # 336 \n",
    "vsize_tgt = len(en_word2idx) # 201\n",
    "hdim = 512\n",
    "model = MyTransformer(vsize_src, vsize_tgt, embedding_size, 6, hdim, 4, 4, max_len=256)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a4a14-51e3-42d2-babd-2fd67708cac0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e8a960216e1f9167a4a54e07c15b093",
     "grade": false,
     "grade_id": "cell-e4d856271fb971bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In the cell below, complete the training and validation loops by filling in the blanks as instructed in the code. Once you have implemented the loops, run the cell to train the model for 10 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e63f9b-07b4-4d01-a62d-25b9deafaf5a",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b079c58218c69b7d28877a40c7291ae",
     "grade": false,
     "grade_id": "cell-3e78e5aa606c25be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Train Loss: 0.9324\n",
      "Epoch 1/8, Validation Loss: 0.1498\n",
      "Epoch 2/8, Train Loss: 0.1022\n",
      "Epoch 2/8, Validation Loss: 0.1041\n",
      "Epoch 3/8, Train Loss: 0.0585\n",
      "Epoch 3/8, Validation Loss: 0.0988\n",
      "Epoch 4/8, Train Loss: 0.0427\n",
      "Epoch 4/8, Validation Loss: 0.0907\n",
      "Epoch 5/8, Train Loss: 0.0359\n",
      "Epoch 5/8, Validation Loss: 0.1021\n",
      "Epoch 6/8, Train Loss: 0.0325\n",
      "Epoch 6/8, Validation Loss: 0.0892\n",
      "Epoch 7/8, Train Loss: 0.0303\n",
      "Epoch 7/8, Validation Loss: 0.1378\n",
      "Epoch 8/8, Train Loss: 0.0291\n",
      "Epoch 8/8, Validation Loss: 0.0995\n",
      "Training completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "num_epochs =8\n",
    "\n",
    "if not skip_training:\n",
    "    epoch_train_losses = []\n",
    "    epoch_validation_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model = model.to(device)\n",
    "        model.train()  # Set model to training mode\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "        for src_batch, tgt_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # set input source as src_batch\n",
    "            src_batch = src_batch.to(device)\n",
    "            tgt_batch = tgt_batch.to(device)\n",
    "            # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
    "            tgt_input = tgt_batch[:, :-1]\n",
    "            # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
    "            tgt_expected = tgt_batch[:, 1:]\n",
    "            # use input source and input target (tgt_input) as input to the model\n",
    "            # expexted target will be used in loss to compare it with the model output.\n",
    "            # Remember to use padding and target causal masks on the model call:\n",
    "            # get padding mask of source,\n",
    "            src_padding_mask = model.create_pad_mask(src_batch)\n",
    "            # get padding mask of input target, convert it to float (.float()),\n",
    "            tgt_padding_mask = model.create_pad_mask(tgt_input).float()\n",
    "            # get tgt_mask of input target,\n",
    "            tgt_mask = model.get_tgt_mask(tgt_input)\n",
    "            # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
    "            _, output = model(\n",
    "                src_batch,\n",
    "                tgt_input,\n",
    "                src_padding_mask=src_padding_mask,\n",
    "                tgt_padding_mask=tgt_padding_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            \n",
    "            output = output.to(device)\n",
    "            output = output.contiguous().view(-1, vsize_tgt)\n",
    "            tgt_expected = tgt_expected.contiguous().view(-1)    \n",
    "            \n",
    "            loss = criterion(output, tgt_expected)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_samples += src_batch.shape[0]\n",
    "    \n",
    "        epoch_train_loss = total_loss / len(train_loader)\n",
    "        epoch_train_loss = round(epoch_train_loss, 4)\n",
    "        epoch_train_losses.append(epoch_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss}\")\n",
    "        \n",
    "        ################################################################\n",
    "        \n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        num_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for src_batch, tgt_batch in val_loader:\n",
    "                src_batch = src_batch.to(device)\n",
    "                tgt_batch = tgt_batch.to(device)\n",
    "            \n",
    "                tgt_input = tgt_batch[:, :-1]\n",
    "                tgt_expected = tgt_batch[:, 1:]\n",
    "\n",
    "                src_padding_mask = model.create_pad_mask(src_batch)\n",
    "                tgt_padding_mask = model.create_pad_mask(tgt_input).float()\n",
    "                tgt_mask = model.get_tgt_mask(tgt_input)\n",
    "            \n",
    "                _, output = model(\n",
    "                    src_batch,\n",
    "                    tgt_input,\n",
    "                    src_padding_mask=src_padding_mask,\n",
    "                    tgt_padding_mask=tgt_padding_mask,\n",
    "                    tgt_mask=tgt_mask\n",
    "                )\n",
    "                \n",
    "                output = output.to(device)\n",
    "                output = output.contiguous().view(-1, vsize_tgt)\n",
    "                tgt_expected = tgt_expected.contiguous().view(-1)  \n",
    "                loss = criterion(output, tgt_expected)\n",
    "                validation_loss += loss.item()\n",
    "                num_samples += src_batch.shape[0]\n",
    "                \n",
    "            epoch_validation_loss = validation_loss / len(val_loader)\n",
    "            epoch_validation_loss = round(epoch_validation_loss, 4)\n",
    "            epoch_validation_losses.append(epoch_validation_loss)\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {epoch_validation_loss}\")\n",
    "        torch.save(model.state_dict(), 'model.pth')   \n",
    "            \n",
    "    print(\"Training completed.\")\n",
    "    torch.save(model.state_dict(), 'model.pth')        \n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epochs, epoch_train_losses, label='Train Loss', color='blue', marker='o')\n",
    "    plt.plot(epochs, epoch_validation_losses, label='Validation Loss', color='red', marker='x')\n",
    "    plt.title('Train vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d97d50-f344-4bd0-9933-31e0967db8ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cd6f4b79c9eb03096892f79e8f40433",
     "grade": false,
     "grade_id": "cell-c54877793b096ca1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 4: Autoregressive Translation (5 points)\n",
    "\n",
    "Finally, we are going to use the trained model to perform an actual translation task, translating French sentences into English. Exciting!\n",
    "\n",
    "The inference works in an autoregressive manner. This means that, during the translation process, the model generates each token in the target sequence one at a time, using the previously generated token as input for predicting the next one. At each step, the model uses the encoded source sentence along with the target sequence generated so far to predict the next word. This approach allows the model to produce the translation step by step, instead of generating the entire sequence at once.\n",
    "\n",
    "The steps for translation are as follows:\n",
    "\n",
    "**Source Sentence Encoding:** First, we obtain the source sequence embedding and pass it through the encoder to obtain its encoded representation.\n",
    "\n",
    "**Initializing Target Sentence with <SOS> Token:** We initialize the target sentence with the special <SOS> (Start Of Sentence) token, which indicates the beginning of the translation.\n",
    "\n",
    "**Autoregressive Loop to Translate Target Tokens One at a Time:** We enter a loop where the model predicts the next token in the sequence based on the previously generated token and the encoded source sentence. This loop continues until the model predicts the <EOS> (End Of Sentence) token or the maximum sequence length is reached.\n",
    "\n",
    "In the cell below, fill in the blanks as instructed to create the translation loop for the provided example sentences. Once you have completed the template, run it and observe the printed translation results. \n",
    "\n",
    "Remeber to submit **'translation.npy'** to Moodle along with your other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b511cb3-8a3d-4d83-b403-ffb9f4b65f5e",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d107bba2e8b29eabdd5bde898afb0b",
     "grade": false,
     "grade_id": "cell-4dae7ac8dd1330c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_sentence: new jersey est parfois calme pendant l' automne.\n",
      "translated_sentence: new jersey is sometimes quiet during autumn <EOS>\n",
      "----------\n",
      "original_sentence: california est généralement calme en mars.\n",
      "translated_sentence: california is usually quiet during march <EOS>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "seq_len=10\n",
    "start_token=1\n",
    "end_token=2\n",
    "model.eval()  \n",
    "\n",
    "# Convert src_sentence to tokenized integers in the vocabulary dictionary \n",
    "example_source_sentences = [\"new jersey est parfois calme pendant l' automne.\", \"california est généralement calme en mars.\"]\n",
    "example_tokenized = tokenize(example_source_sentences)\n",
    "src_sentences = []\n",
    "for ex in example_tokenized:\n",
    "    ex_inds = []\n",
    "    for t in ex:\n",
    "        t_ind = fr_word2idx [t]\n",
    "        ex_inds.append(t_ind)\n",
    "    src_sentences.append(ex_inds)    \n",
    "\n",
    "translated_sequences = []\n",
    "for counter, src_sentence in enumerate(src_sentences):    \n",
    "    # Convert source tokens to Tensor \n",
    "    src_tensor = torch.tensor(src_sentence, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, src_seq_length)\n",
    "    \n",
    "    # 1. create src_padding_mask\n",
    "    src_padding_mask = model.create_pad_mask(src_tensor)\n",
    "    # 2. get \"memory\" by passing source with create src_padding_mask through encode block (model.encode)\n",
    "    memory = model.encode(src_tensor, src_padding_mask)\n",
    "    \n",
    "    # initialize the predicted tgt_tokens (translation) with start token\n",
    "    tgt_tokens = torch.ones(1, 1).fill_(start_token).type(torch.long).to(device) #(1,1)\n",
    "\n",
    "    for i in range(seq_len-1):\n",
    "        # 1. Mask out the unpredicted tokens in the target (i.e., get tgt_mask)\n",
    "        tgt_mask = model.get_tgt_mask(tgt_tokens)\n",
    "        # 2. get output by passing target (the generated part up to current `i`) and memory to decode block (model.decode)\n",
    "        decoded_output = model.decode(\n",
    "        tgt_tokens,\n",
    "        memory,\n",
    "        tgt_mask=tgt_mask,\n",
    "        tgt_padding_mask=None\n",
    "    )\n",
    "\n",
    "        # 4. get a probability vector by passing output through linear layer (projection to vocabulary size)\n",
    "        output_logits = model.fc_out(decoded_output)\n",
    "        # 5. use \"torch.max\" to get the index of the predicted word\n",
    "        next_token_logits = output_logits[:, -1, :]\n",
    "        _, next_token = torch.max(next_token_logits, dim=1)\n",
    "        # 6. Convert it to a tensor on device (name it as \"next_tgt_item\")\n",
    "        next_tgt_item = next_token.unsqueeze(0)\n",
    "        # 7. add \"next_tgt_item\" to tgt_tokens (use torch.cat)\n",
    "        tgt_tokens = torch.cat([tgt_tokens, next_tgt_item], dim=1)\n",
    "        # 8. Stop (break) if \"end_token\" is generated\n",
    "        if next_token.item() == end_token:\n",
    "            break\n",
    "    \n",
    "    translated_tokens = tgt_tokens.squeeze().tolist()\n",
    "    translated_sentence = ' '.join ([en_idx2word[i] for i in translated_tokens[1:]])\n",
    "    translated_sequences.append(translated_tokens)\n",
    "    print(\"original_sentence:\", example_source_sentences[counter])\n",
    "    print(\"translated_sentence:\", translated_sentence)\n",
    "    print(10*'-')\n",
    "\n",
    "np.save('translation.npy', np.array(translated_sequences, dtype=object))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
